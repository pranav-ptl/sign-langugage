{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## What is MediaPipe ?\n![image](https://google.github.io/mediapipe/images/mediapipe_small.png)\n\nMediaPipe offers ready-to-use yet customizable Python solutions as a prebuilt Python package.\n\nRefer - [here](https://google.github.io/mediapipe/)","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Install Libraries and Import Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install mediapipe opencv-python","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:13.852081Z","iopub.execute_input":"2022-11-07T01:23:13.852696Z","iopub.status.idle":"2022-11-07T01:23:28.055629Z","shell.execute_reply.started":"2022-11-07T01:23:13.852556Z","shell.execute_reply":"2022-11-07T01:23:28.054439Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting mediapipe\n  Downloading mediapipe-0.8.11-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.5 MB)\n\u001b[K     |████████████████████████████████| 31.5 MB 231 kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (4.5.3.56)\nRequirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.7/site-packages (from mediapipe) (21.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mediapipe) (1.19.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from mediapipe) (3.4.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from mediapipe) (0.14.0)\nRequirement already satisfied: opencv-contrib-python in /opt/conda/lib/python3.7/site-packages (from mediapipe) (4.5.3.56)\nRequirement already satisfied: protobuf<4,>=3.11 in /opt/conda/lib/python3.7/site-packages (from mediapipe) (3.18.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py->mediapipe) (1.16.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mediapipe) (2.4.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mediapipe) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mediapipe) (1.3.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mediapipe) (2.8.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mediapipe) (8.2.0)\nInstalling collected packages: mediapipe\nSuccessfully installed mediapipe-0.8.11\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import mediapipe as mp # Import mediapipe\nimport cv2 # Import opencv\nimport csv\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:28.057620Z","iopub.execute_input":"2022-11-07T01:23:28.058043Z","iopub.status.idle":"2022-11-07T01:23:29.490767Z","shell.execute_reply.started":"2022-11-07T01:23:28.057982Z","shell.execute_reply":"2022-11-07T01:23:29.489685Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Define Utils","metadata":{}},{"cell_type":"code","source":"mp_drawing = mp.solutions.drawing_utils # For Drawing the cordinates\nmp_hands = mp.solutions.hands # Solution specific for hand coordinate","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.492329Z","iopub.execute_input":"2022-11-07T01:23:29.492696Z","iopub.status.idle":"2022-11-07T01:23:29.498723Z","shell.execute_reply.started":"2022-11-07T01:23:29.492642Z","shell.execute_reply":"2022-11-07T01:23:29.497518Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Make some Detection","metadata":{}},{"cell_type":"code","source":"cap = cv2.VideoCapture(0)\nwith mp_hands.Hands(min_detection_confidence=0.5,min_tracking_confidence=0.5) as hands:\n    while cap.isOpened():\n        success, image = cap.read()\n\n        # Flip the image horizontally for a later selfie-view display, and convert\n        # the BGR image to RGB.\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        # To improve performance, optionally mark the image as not writeable to\n        # pass by reference.\n        image.flags.writeable = False\n        results = hands.process(image)\n\n        # Draw the hand annotations on the image.\n        image.flags.writeable = True\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n\n\n\n#         image_height, image_width, _ = image.shape\n\n        if results.multi_hand_landmarks:\n            for hand_landmarks in results.multi_hand_landmarks:\n                mp_drawing.draw_landmarks(\n                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n        cv2.imshow('MediaPipe Hands', image)\n        if cv2.waitKey(10) & 0xFF == ord('q'):\n            break\ncap.release()\n# cv2.destroyAllWindows()","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:55.351737Z","iopub.execute_input":"2022-11-07T01:23:55.352349Z","iopub.status.idle":"2022-11-07T01:23:55.437593Z","shell.execute_reply.started":"2022-11-07T01:23:55.352310Z","shell.execute_reply":"2022-11-07T01:23:55.436766Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"[ WARN:0] global /tmp/pip-req-build-fvfwe_ss/opencv/modules/videoio/src/cap_v4l.cpp (890) open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Step 4: Capture Landmarks & Export to CSV","metadata":{}},{"cell_type":"code","source":"import csv\nimport os\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.609745Z","iopub.execute_input":"2022-11-07T01:23:29.610300Z","iopub.status.idle":"2022-11-07T01:23:29.614772Z","shell.execute_reply.started":"2022-11-07T01:23:29.610255Z","shell.execute_reply":"2022-11-07T01:23:29.613909Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"num_coords = len(hand_landmarks.landmark)\nnum_coords","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.616325Z","iopub.execute_input":"2022-11-07T01:23:29.616850Z","iopub.status.idle":"2022-11-07T01:23:29.761192Z","shell.execute_reply.started":"2022-11-07T01:23:29.616792Z","shell.execute_reply":"2022-11-07T01:23:29.758574Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_20/3845432385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhand_landmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnum_coords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'hand_landmarks' is not defined"],"ename":"NameError","evalue":"name 'hand_landmarks' is not defined","output_type":"error"}]},{"cell_type":"code","source":"landmarks = ['class']\nfor val in range(1, num_coords+1):\n    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val)]","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.763129Z","iopub.status.idle":"2022-11-07T01:23:29.763530Z","shell.execute_reply.started":"2022-11-07T01:23:29.763324Z","shell.execute_reply":"2022-11-07T01:23:29.763343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmarks","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.764961Z","iopub.status.idle":"2022-11-07T01:23:29.765372Z","shell.execute_reply.started":"2022-11-07T01:23:29.765180Z","shell.execute_reply":"2022-11-07T01:23:29.765200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('coords.csv', mode='w', newline='') as f:\n    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n    csv_writer.writerow(landmarks)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.767420Z","iopub.status.idle":"2022-11-07T01:23:29.768409Z","shell.execute_reply.started":"2022-11-07T01:23:29.768126Z","shell.execute_reply":"2022-11-07T01:23:29.768170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_name = \"Three\"","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.770228Z","iopub.status.idle":"2022-11-07T01:23:29.770614Z","shell.execute_reply.started":"2022-11-07T01:23:29.770421Z","shell.execute_reply":"2022-11-07T01:23:29.770449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cap = cv2.VideoCapture(0)\nwith mp_hands.Hands(min_detection_confidence=0.5,min_tracking_confidence=0.5) as hands:\n    while cap.isOpened():\n        success, image = cap.read()\n        \n\n        # Flip the image horizontally for a later selfie-view display, and convert\n        # the BGR image to RGB.\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        # To improve performance, optionally mark the image as not writeable to\n        # pass by reference.\n        image.flags.writeable = False\n        results = hands.process(image)\n\n        # Draw the hand annotations on the image.\n        image.flags.writeable = True\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n\n\n\n        image_height, image_width, _ = image.shape\n\n        if results.multi_hand_landmarks:\n            for hand_landmarks in results.multi_hand_landmarks:\n                mp_drawing.draw_landmarks(\n                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n        \n        try:\n            hand = hand_landmarks.landmark\n            hand_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand]).flatten())\n            \n            row = hand_row\n            \n            # Append class name \n            row.insert(0, class_name)\n            \n            # Export to CSV\n            with open('coords.csv', mode='a', newline='') as f:\n                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n                csv_writer.writerow(row) \n            \n        except:\n            pass\n            \n   \n        cv2.imshow('MediaPipe Hands 4', image)\n        if cv2.waitKey(10) & 0xFF == ord('q'):\n            break\ncap.release()\ncv2.destroyAllWindows()","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.772410Z","iopub.status.idle":"2022-11-07T01:23:29.772781Z","shell.execute_reply.started":"2022-11-07T01:23:29.772593Z","shell.execute_reply":"2022-11-07T01:23:29.772616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 5: Read in Collected Data and Process","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.774667Z","iopub.status.idle":"2022-11-07T01:23:29.775642Z","shell.execute_reply.started":"2022-11-07T01:23:29.775422Z","shell.execute_reply":"2022-11-07T01:23:29.775448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('coords.csv')\n\nX = df.drop('class', axis=1) # features\ny = df['class'] # target value\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.776927Z","iopub.status.idle":"2022-11-07T01:23:29.777301Z","shell.execute_reply.started":"2022-11-07T01:23:29.777104Z","shell.execute_reply":"2022-11-07T01:23:29.777132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 6: Train Custom Model Using Scikit Learn","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.pipeline import make_pipeline \nfrom sklearn.preprocessing import StandardScaler \n\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.778806Z","iopub.status.idle":"2022-11-07T01:23:29.779218Z","shell.execute_reply.started":"2022-11-07T01:23:29.779010Z","shell.execute_reply":"2022-11-07T01:23:29.779042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npipelines = {\n    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n}","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.781161Z","iopub.status.idle":"2022-11-07T01:23:29.781624Z","shell.execute_reply.started":"2022-11-07T01:23:29.781414Z","shell.execute_reply":"2022-11-07T01:23:29.781439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 7: Train Machine Learning Classification Model","metadata":{}},{"cell_type":"code","source":"fit_models = {}\nfor algo, pipeline in pipelines.items():\n    model = pipeline.fit(X_train, y_train)\n    fit_models[algo] = model","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.783379Z","iopub.status.idle":"2022-11-07T01:23:29.783759Z","shell.execute_reply.started":"2022-11-07T01:23:29.783556Z","shell.execute_reply":"2022-11-07T01:23:29.783586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_models['rc'].predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.785323Z","iopub.status.idle":"2022-11-07T01:23:29.786112Z","shell.execute_reply.started":"2022-11-07T01:23:29.785890Z","shell.execute_reply":"2022-11-07T01:23:29.785919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 8: Evaluate and Serialize Model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score # Accuracy metrics \nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.788566Z","iopub.status.idle":"2022-11-07T01:23:29.788990Z","shell.execute_reply.started":"2022-11-07T01:23:29.788749Z","shell.execute_reply":"2022-11-07T01:23:29.788777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor algo, model in fit_models.items():\n    yhat = model.predict(X_test)\n    print(algo, accuracy_score(y_test, yhat))","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.790375Z","iopub.status.idle":"2022-11-07T01:23:29.790723Z","shell.execute_reply.started":"2022-11-07T01:23:29.790541Z","shell.execute_reply":"2022-11-07T01:23:29.790564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_models['rf'].predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.792365Z","iopub.status.idle":"2022-11-07T01:23:29.792730Z","shell.execute_reply.started":"2022-11-07T01:23:29.792541Z","shell.execute_reply":"2022-11-07T01:23:29.792567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwith open('Numbers.pkl', 'wb') as f:\n    pickle.dump(fit_models['rf'], f)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.798325Z","iopub.status.idle":"2022-11-07T01:23:29.798829Z","shell.execute_reply.started":"2022-11-07T01:23:29.798623Z","shell.execute_reply":"2022-11-07T01:23:29.798650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 9: Make Detections with Model","metadata":{}},{"cell_type":"code","source":"with open('Numbers.pkl', 'rb') as f:\n    model = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.800170Z","iopub.status.idle":"2022-11-07T01:23:29.800529Z","shell.execute_reply.started":"2022-11-07T01:23:29.800345Z","shell.execute_reply":"2022-11-07T01:23:29.800370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cap = cv2.VideoCapture(0)\nwith mp_hands.Hands(min_detection_confidence=0.5,min_tracking_confidence=0.5) as hands:\n    while cap.isOpened():\n        success, image = cap.read()\n       \n        # Flip the image horizontally for a later selfie-view display, and convert\n        # the BGR image to RGB.\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        # To improve performance, optionally mark the image as not writeable to\n        # pass by reference.\n        image.flags.writeable = False\n        results = hands.process(image)\n\n        # Draw the hand annotations on the image.\n        image.flags.writeable = True\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n\n\n\n#         image_height, image_width, _ = image.shape\n\n        if results.multi_hand_landmarks:\n            for hand_landmarks in results.multi_hand_landmarks:\n                mp_drawing.draw_landmarks(\n                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n        try:\n            hand = hand_landmarks.landmark\n            hand_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand]).flatten())\n\n            row = hand_row\n#             print(row)\n\n\n            X = pd.DataFrame([row])\n            hand_language_class = model.predict(X)[0]\n            hand_language_prob = model.predict_proba(X)[0]\n            print(hand_language_class, hand_language_prob)\n\n\n\n            coords = tuple(np.multiply(\n                            np.array(\n                                (hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x, \n                                 hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y))\n                        , [640,480]).astype(int))\n\n            cv2.rectangle(image, \n                          (coords[0], coords[1]+5), \n                          (coords[0]+len(hand_language_class)*20, coords[1]-30), \n                          (245, 117, 16), -1)\n            cv2.putText(image, hand_language_class, coords, \n                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n\n            # Get status box\n            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n\n            # Display Class\n            cv2.putText(image, 'CLASS'\n                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n            cv2.putText(image, hand_language_class.split(' ')[0]\n                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n\n            # Display Probability\n            cv2.putText(image, 'PROB'\n                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n            cv2.putText(image, str(round(hand_language_prob[np.argmax(hand_language_prob)],2))\n                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n\n        except:\n            pass\n            \n   \n        cv2.imshow('MediaPipe Hands 2', image)\n        if cv2.waitKey(10) & 0xFF == ord('q'):\n            break\ncap.release()\ncv2.destroyAllWindows()","metadata":{"execution":{"iopub.status.busy":"2022-11-07T01:23:29.802435Z","iopub.status.idle":"2022-11-07T01:23:29.802802Z","shell.execute_reply.started":"2022-11-07T01:23:29.802607Z","shell.execute_reply":"2022-11-07T01:23:29.802632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}